{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbbd596",
   "metadata": {},
   "source": [
    "This is the neural network based on DenseNet and LearnableResizer architectures used for the classification improvement on the dataset from Skrabanek and Zahradnikova Jr., 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import ReLU, concatenate, LeakyReLU, Add,Resizing, Rescaling\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "#the model architecture\n",
    "\n",
    "def conv_block(x, filters, kernel_size, strides, activation=LeakyReLU(0.2)):\n",
    "    x = Conv2D(filters, kernel_size, strides, padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def res_block(x):\n",
    "    inputs = x\n",
    "    x = conv_block(x, 16, 3, 1)\n",
    "    x = conv_block(x, 16, 3, 1, activation=None)\n",
    "    return Add()([inputs, x])\n",
    "\n",
    "\n",
    "def LearnableResizer(x,filters=16, num_res_blocks=1, interpolation=\"bilinear\"):\n",
    "\n",
    "    naive_resize = Resizing(256,256, interpolation=interpolation)(x)\n",
    "\n",
    "    x = Conv2D(filters=filters, kernel_size=7, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(filters=filters, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    bottleneck = Resizing(256,256, interpolation=interpolation)(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = res_block(bottleneck)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filters, kernel_size=3, strides=1, padding=\"same\", use_bias=False\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Add()([bottleneck, x])\n",
    "\n",
    "    # Final resized image.\n",
    "    x = Conv2D(filters=3, kernel_size=7, strides=1, padding=\"same\")(x)\n",
    "    final_resize = Add()([naive_resize, x])\n",
    "\n",
    "    return final_resize\n",
    "\n",
    "def DenseNetNew(k, comp_f):\n",
    "        #batch norm + relu + conv\n",
    "    def bn_rl_conv(x,filters,kernel=1,strides=1):\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)\n",
    "        return x\n",
    "    \n",
    "    def dense_block(x, repetition, filters):\n",
    "        \n",
    "        for _ in range(repetition):\n",
    "            y = bn_rl_conv(x, 4*filters)\n",
    "            y = bn_rl_conv(y, filters, 3)\n",
    "            x = concatenate([y,x])\n",
    "        return x\n",
    "        \n",
    "    def transition_layer(x,m):\n",
    "        \n",
    "        x = bn_rl_conv(x, m )\n",
    "        x = AvgPool2D(2, strides = 2, padding = 'same')(x)\n",
    "        return x\n",
    "    \n",
    "    inputs = Input ((None,None,1))\n",
    "    x = Rescaling(scale=1.0 / 255)(inputs)\n",
    "    x = LearnableResizer(x)\n",
    "    x = Conv2D(2*k, 7, strides = 2, padding = 'same')(x)\n",
    "    x = MaxPool2D(3, strides = 2, padding = 'same')(x)\n",
    "    m = 2*k\n",
    "    \n",
    "    for i,repetition in enumerate([6,9,12,15,18]):\n",
    "        d = dense_block(x, repetition, k)\n",
    "        m = np.floor((m + repetition*k)*comp_f)\n",
    "        if i != 5:\n",
    "            x = transition_layer(d,m)\n",
    "    x = GlobalAveragePooling2D()(d)\n",
    "    output = Dense(6, activation = 'softmax', kernel_regularizer=\"l2\")(x)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "modelnew = DenseNetNew(15,0.5)\n",
    "modelnew.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of model training\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\"T-1024-B-Small\", batch_size = 6, shuffle = True, image_size = (1024,1024),color_mode = \"grayscale\",label_mode=\"categorical\")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\"E-1024-A-Small\", batch_size = 6, shuffle = False, image_size = (1024,1024),color_mode = \"grayscale\",label_mode=\"categorical\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-4, beta_1 = 0.95, beta_2 = 0.999)\n",
    "modelnew.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"RescaledModel_{epoch}.h5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose = 1,\n",
    "    save_best_only=True)\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen so far.\n",
    "modelnew.fit(train_ds,epochs=5, callbacks=[model_checkpoint_callback], validation_data=test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
